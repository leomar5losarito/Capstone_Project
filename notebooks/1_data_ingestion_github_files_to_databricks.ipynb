{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3eb33256-bd1c-4990-808b-c227aa307385",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "\n",
    "# Get files from GitHub\n",
    "\n",
    "import requests\n",
    "\n",
    "raw_files_batch = [\n",
    "    \"https://raw.githubusercontent.com/leomar5losarito/Capstone_Project/main/data/claims_batch.csv\",\n",
    "    \"https://raw.githubusercontent.com/leomar5losarito/Capstone_Project/main/data/diagnosis_ref.csv\",\n",
    "    \"https://raw.githubusercontent.com/leomar5losarito/Capstone_Project/main/data/members.csv\",\n",
    "    \"https://raw.githubusercontent.com/leomar5losarito/Capstone_Project/main/data/providers.json\"\n",
    "]\n",
    "raw_files_stream = [\n",
    "    \"https://raw.githubusercontent.com/leomar5losarito/Capstone_Project/main/data/claims_stream.json\"\n",
    "]\n",
    "\n",
    "# Target paths\n",
    "volume_raw_file_path = \"/Volumes/leomar/1bronze/github_files/\"\n",
    "autoloader_path = \"/Volumes/leomar/1bronze/autoloader_files/\"\n",
    "\n",
    "# Make autoloader_path if not exists\n",
    "dbutils.fs.mkdirs(autoloader_path)\n",
    "print(f\"Path exists : {autoloader_path}\")\n",
    "\n",
    "# Download the streaming file\n",
    "for url in raw_files_stream:\n",
    "    try:\n",
    "        response1 = requests.get(url)\n",
    "        filename = url.split(\"/\")[-1]\n",
    "        response1.raise_for_status() # Raises an exception for HTTP errors \n",
    "        with open(f\"{autoloader_path}{filename}\", \"wb\") as f1:\n",
    "            f1.write(response1.content)\n",
    "            print(f\"Writing {filename} to DBFS for Auto Loader: {autoloader_path}\")\n",
    "    except Exception as e:\n",
    "            print(f\"An unexpected error occurred with {filename}: {e}\\n\")\n",
    "\n",
    "# Download the batch files\n",
    "for url in raw_files_batch:\n",
    "    try:\n",
    "        response2 = requests.get(url)\n",
    "        filename = url.split(\"/\")[-1]\n",
    "        response2.raise_for_status() # Raises an exception for HTTP errors \n",
    "        with open(f\"{volume_raw_file_path}{filename}\", \"wb\") as f2:\n",
    "            f2.write(response2.content)\n",
    "            print(f\"Writing {filename} to Volume: {volume_raw_file_path}\")\n",
    "    except Exception as e:\n",
    "            print(f\"An unexpected error occurred with {filename}: {e}\\n\")\n",
    "\n",
    "print(\"Successfully transferred all files\\n\")\n",
    "\n",
    "#Verify files \n",
    "print(\"Files in Volume (.../github_files/...):\")\n",
    "display(dbutils.fs.ls(volume_raw_file_path))\n",
    "\n",
    "print(\"\\nFiles in DBFS (dbfs:.../autoloader_files/...) - for Auto Loader:\")\n",
    "display(dbutils.fs.ls(autoloader_path))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "1_data_ingestion_github_files_to_databricks",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
